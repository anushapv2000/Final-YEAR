# -*- coding: utf-8 -*-
"""anime-gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDOFsCGNMNQLJzKlT-iXdha18g8JLvAT

Animegan without transfer learning
"""

import tensorflow as tf

!sudo mkdir /content/onedrive
!nohup rclone â€” vfs-cache-mode writes mount onedrive: /content/onedrive &

!pip install pytorch-lightning

# Commented out IPython magic to ensure Python compatibility.
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import torchvision.transforms as T
import os
import torch
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
# %matplotlib inline
import torch.nn.functional as F
#import pytorch_lightning as pl


random_seed = 42
torch.manual_seed(random_seed)

BATCH_SIZE=128
AVAIL_GPUS = min(1, torch.cuda.device_count())
NUM_WORKERS=int(os.cpu_count() / 2)

from google.colab import drive 
drive.mount('/content/drive')

DATA_DIR ='/content/drive/MyDrive/Documents/DOWNLOADS'
print(len(os.listdir(DATA_DIR )))

#DATA_DIR = '/content/drive/Othercomputers/My Laptop/Documents/Python Scripts/cropped_3'
#print(len(os.listdir(DATA_DIR )))

os.listdir(DATA_DIR)

cp -r  '/content/drive/Othercomputers/My Laptop/Documents/Python Scripts/cropped_3' '/content/images'

DATA_DIR='/content/images/'

rm -rvf /content/cropped/.ipynb_checkpoints

print(os.listdir(DATA_DIR ))

image_size=64
batch_size=128
stats=((0.5,0.5,0.5),(0.5,0.5,0.5))

#@title
train_ds = ImageFolder(DATA_DIR, transform= T.Compose([
            T.Resize(image_size),
            T.CenterCrop(image_size),
            T.ToTensor(),
            T.Normalize(*stats)
]))
train_dl = DataLoader(train_ds, batch_size , shuffle=True,num_workers=3,pin_memory=True)

len(train_ds)

for i ,l in train_ds:
  print(i.shape)
  break

#@title
def denormalize(images, means, stds):
    means = torch.tensor(means).reshape(1, 3, 1, 1).to(device)
    stds = torch.tensor(stds).reshape(1, 3, 1, 1).to(device)
    return images * stds + means

def show_batch(dl):
    #for images, labels in dl:
        #print(images.shape)
        fig, ax = plt.subplots(figsize=(12, 12))
        ax.set_xticks([]); ax.set_yticks([])
        denorm_images = denormalize(dl, *stats)
        ax.imshow(make_grid(denorm_images[:32], nrow=8).permute(1,2,0))
     #   break

#@title
def denormalize(images, means, stds):
    images=images.to('cpu')
    means = torch.tensor(means).reshape(1, 3, 1, 1).to('cpu')
    stds = torch.tensor(stds).reshape(1, 3, 1, 1).to('cpu')
    return images * stds + means

def show_batch(dl):
    for images, labels in dl:
        #print(images.shape)
        #dl=images.unsqueeze(0)
        fig, ax = plt.subplots(figsize=(12, 12))
        ax.set_xticks([]); ax.set_yticks([])
        denorm_images = denormalize(images.detach(), *stats)
        ax.imshow(make_grid(denorm_images[:32], nrow=8).permute(1,2,0))
        break

show_batch(train_dl)

#@title
def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    
def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        

    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl: 
            yield to_device(b, self.device)
    def __len__(self):
      return len(self.dl)

"""# anime-gan

Use the "Run" button to execute the code.
"""

device = get_default_device()
device

train_dl=DeviceDataLoader(train_dl,device)

import torch.nn as nn

discriminator = nn.Sequential(
    
  nn.Conv2d(3,64,kernel_size=4, stride = 2, padding=1, bias=False),
  nn.BatchNorm2d(64),
  nn.LeakyReLU(0.2,inplace=True),
  
  nn.Conv2d(64,128,kernel_size=4, stride = 2, padding=1, bias=False),
  nn.BatchNorm2d(128),
  nn.LeakyReLU(0.2,inplace=True),

  nn.Conv2d(128,256,kernel_size=4, stride = 2, padding=1, bias=False),
  nn.BatchNorm2d(256),
  nn.LeakyReLU(0.2,inplace=True),

  nn.Conv2d(256,512,kernel_size=4, stride = 2, padding=1, bias=False),
  nn.BatchNorm2d(512),
  nn.LeakyReLU(0.2,inplace=True),

  nn.Conv2d(512,1,kernel_size=4, stride = 1, padding=0, bias=False),
  nn.Flatten(),
  nn.Sigmoid()

)

print(discriminator.parameters)

model = to_device(discriminator, device)
model

latent_size=128

generator=nn.Sequential(
          nn.ConvTranspose2d(latent_size, 512, kernel_size=4,stride =1, padding=0,bias=False), 
          nn.BatchNorm2d(512), 
          nn.ReLU(True),

          nn.ConvTranspose2d(512,256, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.BatchNorm2d(256), 
          nn.ReLU(True),

          nn.ConvTranspose2d(256,128, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.BatchNorm2d(128), 
          nn.ReLU(True),

          nn.ConvTranspose2d(128,64, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.BatchNorm2d(64), 
          nn.ReLU(True),

          nn.ConvTranspose2d(64,3, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.Tanh()
)

generator=to_device(generator,device)

generator

xb=torch.randn(2,latent_size,1,1,device=device)

xb.shape

fake_img = generator(xb)
print(fake_img.shape)
#show_batch(fake_img)

def tr_discrim(real_images,opt_d):
  opt_d.zero_grad()

  #Pass real images through discriminator
  real_preds = discriminator (real_images)
  real_targets = torch.ones (real_images. size (0) , 1, device=device )
  real_loss = F.binary_cross_entropy (real_preds, real_targets)
  real_score = torch.mean(real_preds). item ()
  #Generate fake images
  latent =  torch.randn (batch_size, latent_size, 1, 1, device=device )
  fake_images = generator( latent)
  #Pass fake images through discriminator
  fake_targets= torch.zeros(fake_images. size (0), 1, device=device)
  fake_preds = discriminator(fake_images)
  fake_loss = F.binary_cross_entropy ( fake_preds, fake_targets)
  fake_score = torch.mean(fake_preds).item()
  
  loss = real_loss+fake_loss
  loss.backward()
  opt_d.step()
  return loss.item(), real_score, fake_score

#Because of this, when you start your training loop, ideally you
#should zero out the gradients so that you do the parameter update 
#correctly. Otherwise, the gradient would be a combination of the old 
#gradient, which you have already used to update your model parameters,
# and the newly-computed gradient. It would therefore point in some 
#other direction than the intended direction towards the minimum 
#(or maximum, in case of maximization objectives).
def tr_generator(opt_g):
  opt_g.zero_grad()
  latent = torch.randn(batch_size, latent_size, 1,1 , device=device)
  fake_imgs =  generator(latent)

  fool_discrim_preds = discriminator(fake_imgs)
  fool_discrim_target = torch.ones(batch_size,1, device=device)
  loss = F.binary_cross_entropy(fool_discrim_preds,fool_discrim_target)

  loss.backward()
  opt_g.step()
  return loss.item()

from torchvision.utils import save_image

sample_dir = 'generated'

os.makedirs(sample_dir,exist_ok=True)

def save_generated(index,latent_tensors,show=True):
  fake_imgs = generator(latent_tensors)
  fake_label = 'img_generated-{0:0=4d}.png'.format(index) 
  save_image(denormalize(fake_imgs,*stats),os.path.join(sample_dir,fake_label),nrow=8)
  if show:
    fig,ax = plt.subplots(figsize=(8,8))
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(make_grid(fake_imgs.cpu().detach(),nrow=8).permute(1,2,0))

fake_imgs = generator(xb)

fake_label = 'img_generated-{0:0=4d}.png'.format(1)

save_image(denormalize(fake_imgs,*stats),os.path.join(sample_dir,fake_label),nrow=8)

xr = torch.randn(64, latent_size, 1,1,device=device)

save_generated(0,xr)

from tqdm.notebook import tqdm
import torch.nn.functional as F
import time

def fit(epochs, lr, start_idx=1):
   torch.cuda.empty_cache()

   losses_g = []
   losses_d = []
   real_scores = []
   fake_scores = []

   opt_d = torch.optim.Adam(discriminator.parameters(),lr=lr, betas = (0.5, 0.999))
   opt_g = torch.optim.Adam(generator.parameters(),lr=lr , betas = (0.5,0.999))
   t1=time.time()
   for epoch in range(epochs):
     for real_images, _ in tqdm(train_dl):
       loss_d , real_score, fake_score = tr_discrim(real_images, opt_d)
       loss_g = tr_generator(opt_g)
     
     losses_g.append(loss_g)
     losses_d.append(loss_d)
     real_scores.append(real_score)
     fake_scores.append(fake_score)
      
     print("Epoch[{}/{}], loss_g:{:.4f}, loss_d:{:.4f},real_score:{:.4f}, fake_score:{:.4f} ".format(epoch+1,epochs,loss_g,loss_d,real_score,fake_score))
     
     save_generated(epoch+start_idx,xr,show=False)
   t2=time.time()
   print("time taken",t2-t1)
   return losses_g,  real_scores, fake_scores ,losses_d,

lr = 0.0002
epochs = 100
#metric_values=[]

metric_values_100=metric_values

metric_values.append( fit(epochs, lr))

from google.colab import files
files.download('/content/generated')

!zip -r /content/generated.zip /content/generated







"""RESNET

"""

import torchvision.transforms as T
img_size = 256
DATA_DIR='/content/drive/Othercomputers/My Laptop/Documents/Python Scripts/cropped_3'
images=os.listdir('/content/drive/Othercomputers/My Laptop/Documents/Python Scripts/cropped_3')
from PIL import Image
def open_image(p):
    with open(p,'rb') as file:
        img=Image.open(file)
        return img.convert('RGB')
plt.imshow(open_image(os.path.join(DATA_DIR,images[4])))
plt.imshow(Image.open(os.path.join(DATA_DIR,images[5])))

from torch.utils.data import Dataset
class preprocess(Dataset):
    def __init__(self,root,transform):
        super().__init__()
        self.root=root
        self.files = [f for f in os.listdir(root)]
        self.transform = transform
    def __len__(self):
        return len(self.files)
    def __getitem__(self,i):
        f=self.files[i]
        fp=os.path.join(self.root,f)
        img=self.transform(open_image(fp))
        return img

imagenet_stats =([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])#([0.5,0.5,0.5],[0.5,0.5,0.5])
img_size = 256
dataset = preprocess(DATA_DIR,T.Compose ([
T.Resize (img_size),
T.Pad (8, padding_mode='reflect'),
T.CenterCrop(img_size),
T.ToTensor(),
T.Normalize(*imagenet_stats)]))

def device_available():
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.cuda.device('cpu')
def feed_device(data,device):
    if isinstance(data, (list,tuple)):
        return [feed_device(x, device) for x in data]
    return data.to(device,non_blocking = True)
class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl: 
            yield feed_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)

device = device_available()
device

def denormalize(images, means, stds):
    means = torch.tensor(means).reshape(1, 3, 1, 1)
    stds = torch.tensor(stds).reshape(1, 3, 1, 1)
    return images * stds + means
def denormalize_gpu(images, means, stds):
    means = torch.tensor(means,device=device).reshape(1, 3, 1, 1)
    stds = torch.tensor(stds,device=device).reshape(1, 3, 1, 1)
    return images * stds + means
def show_image(dl):
    #for images, labels in dl:
    if len(dl.shape)==3:
        dl = dl.unsqueeze(0)
    fig, ax = plt.subplots(figsize=(4, 4))
    ax.set_xticks([]); ax.set_yticks([])
    denorm_images = denormalize(dl, *imagenet_stats)
    ax.imshow(make_grid(denorm_images[:64], nrow=8).permute(1,2,0))
     #   break

show_image(dataset[0])

from torch.utils.data import random_split
val_pct = 0.3
val_size = int(val_pct* len (dataset))
train_ds,valid_ds = random_split ( dataset,[len(dataset) - val_size, val_size ])

batch_size = 128
train_dl = DataLoader ( train_ds, batch_size, shuffle=True , num_workers=3 , pin_memory=True)
valid_dl= DataLoader (valid_ds , batch_size*2 , num_workers=4, pin_memory=True)

def show_batch(dl):
    for images in dl:
        fig, ax = plt.subplots(figsize=(4, 4))
        ax.set_xticks([]); ax.set_yticks([])
        denorm_images = denormalize(images, *imagenet_stats)
        ax.imshow(make_grid(denorm_images[:64], nrow=8).permute(1,2,0))
        break

show_batch(valid_dl)

train_dl = DeviceDataLoader(train_dl, device)
valid_dl = DeviceDataLoader(valid_dl, device)

import torch.nn as nn
import torch. nn. functional as F
def accuracy (outputs, labels) :
    preds = torch.max (outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len (preds ) )

class ImageClassificationBase (nn. Module ) :
    def training_step (self, batch) :
        images, labels = batch
        out=self(images)
        loss= F.cross_entropy (out, labels) 
        return loss
    def validate_stop(self, batch):
        valid , _ =batch
        out= self (valid)
        loss = F.cross_entropy (out, _)
        acc = accuracy (out, labels)
        return {'val_loss': loss .detach (), 'val_acc' : acc}

from torchvision import models
class discriminator(nn.Module):
    def __init__(self,pretrained=True):
        super().__init__()
        self.network = models.resnet34(pretrained=pretrained)
        self.network.fc = nn.Linear(self.network.fc.in_features,1)
    def forward(self,xb):
        return self.network(xb)

resnet=models.resnet34(pretrained=True)

discriminator = models.resnet34(pretrained=True)
discriminator.fc = nn.Linear(discriminator.fc.in_features,1)

#print(discriminator.parameters)
discriminator = feed_device(discriminator, device)

latent_size=128
generator=nn.Sequential(
          nn.ConvTranspose2d(latent_size, 512, kernel_size=4,stride =1, padding=0,bias=False), 
          nn.BatchNorm2d(512), 
          nn.ReLU(True),

          nn.ConvTranspose2d(512,256, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.BatchNorm2d(256), 
          nn.ReLU(True),

          nn.ConvTranspose2d(256,128, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.BatchNorm2d(128), 
          nn.ReLU(True),

          nn.ConvTranspose2d(128,64, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.BatchNorm2d(64), 
          nn.ReLU(True),

          nn.ConvTranspose2d(64,3, kernel_size=4,stride =2, padding=1,bias=False), 
          nn.Tanh()
)

generator = to_device(generator, device)

import numpy as np
def tr_discrim(real_images,opt_d):
    opt_d.zero_grad()

    #Pass real images through discriminator  
    real_preds = discriminator (real_images).cpu().detach().numpy()
    real_preds=(real_preds - np.min(real_preds)) / (np.max(real_preds) - np.min(real_preds))
    real_preds=torch.from_numpy(real_preds).to(device)
    real_preds.requires_grad =True
    real_targets = torch.ones (real_images. size (0) , 1,device=device)
    real_loss = F.binary_cross_entropy (real_preds, real_targets)
    real_score = torch.mean(real_preds). item ()
    #Generate fake images
    latent =  torch.randn (batch_size, latent_size, 1, 1,device=device)
    fake_images = generator( latent)
    #Pass fake images through discriminator
    fake_targets= torch.zeros(fake_images. size (0), 1,device=device)
    fake_preds = discriminator(fake_images).cpu().detach().numpy()
    fake_preds=(fake_preds - np.min(fake_preds)) / (np.max(fake_preds) - np.min(fake_preds))
    fake_preds=torch.from_numpy(fake_preds).to(device)
    fake_loss = F.binary_cross_entropy ( fake_preds, fake_targets)
    fake_score = torch.mean(fake_preds).item()

    loss = real_loss+fake_loss
    loss.backward()
    opt_d.step()
    return loss.item(), real_score, fake_score

def tr_generator(opt_g):
    opt_g.zero_grad()
    latent = torch.randn(batch_size, latent_size, 1,1,device=device )
    fake_imgs =  generator(latent)

    fool_discrim_preds = discriminator(fake_imgs).cpu().detach().numpy()
    fool_discrim_preds=(fool_discrim_preds - np.min(fool_discrim_preds)) / (np.max(fool_discrim_preds) - np.min(fool_discrim_preds))
    fool_discrim_preds=torch.from_numpy(fool_discrim_preds).to(device)
    fool_discrim_preds.requires_grad=True
    fool_discrim_target = torch.ones(batch_size,1,device=device)
    loss = F.binary_cross_entropy(fool_discrim_preds,fool_discrim_target)

    loss.backward()
    opt_g.step()
    return loss.item()

sample_dir = 'generated_65_resnet'
os.makedirs(sample_dir,exist_ok=True)

def save_generated(index,latent_tensors,show=True):
    fake_imgs = generator(latent_tensors)
    fake_label = 'img_generated-{0:0=4d}.png'.format(index) 
    save_image(denormalize_gpu(fake_imgs,*imagenet_stats),os.path.join(sample_dir,fake_label),nrow=8)
    if show:
        fig,ax = plt.subplots(figsize=(8,8))
        ax.set_xticks([]); ax.set_yticks([])
        ax.imshow(make_grid(fake_imgs.cpu().detach(),nrow=8).permute(1,2,0))







xr = torch.randn(64, latent_size, 1,1,device=device)

save_generated(0,xr)

def evaluate(model,valid_loader):
    model.eval()
    outputs = [validation_step(model,batch) for batch in valid_loader]
    return validation_epoch_end(outputs)
def fit(epochs, lr, start_idx=1):
    torch.cuda.empty_cache()
    losses_g = []
    losses_d = []
    real_scores = []
    fake_scores = []

    opt_d = torch.optim.Adam(discriminator.parameters(),lr=lr, betas = (0.5, 0.999))
    opt_g = torch.optim.Adam(generator.parameters(),lr=lr , betas = (0.5,0.999))

    for epoch in range(epochs):
        discriminator.train()
        generator.train()
        train_losses=[]
        for real_images in tqdm(train_dl):
            loss_d , real_score, fake_score = tr_discrim(real_images, opt_d)
            loss_g = tr_generator(opt_g)
        
        losses_g.append(loss_g)
        losses_d.append(loss_d)
        real_scores.append(real_score)
        fake_scores.append(fake_score)
      
        print("Epoch[{}/{}], loss_g:{:.4f}, loss_d:{:.4f},real_score:{:.4f}, fake_score:{:.4f} ".format(epoch+1,epochs,loss_g,loss_d,real_score,fake_score))
     
        save_generated(epoch+start_idx,xr,show=False)
    return losses_g, losses_d, real_score, fake_score

lr = 0.0002
epochs = 100

training = fit(epochs, lr)



"""#END RESNET"""

import pandas as pd

df = pd.DataFrame(metric_values)
df.to_csv('metric_values.csv')

metric_values#3054 sec

plt.plot(metric_values[0][0],'-')
plt.plot(metric_values[0][3],'-')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['Generator','Discriminator'])
plt.title('Losses')

plt.plot(metric_values[0][1],'-')
plt.plot(metric_values[0][2],'-')
plt.xlabel('epoch')
plt.ylabel('score')
plt.legend(['Real Scores','Fake scores'])
plt.title('Score')

metric_values[0][3]

#IMAGE TRANSITION
from torch.autograd import Variable
import torchvision.utils as vutils
from __future__ import print_function
from PIL import Image
import random

def convert_img(img_tensor, nrow):
    img_tensor = img_tensor.cpu()
    grid = vutils.make_grid(img_tensor, nrow=nrow, padding=2)
    ndarr = grid.mul(0.5).add(0.5).mul(255).byte().transpose(0, 2).transpose(0, 1).numpy()
    im = Image.fromarray(ndarr)
    return im

a=torch.FloatTensor(8,128,1,1).normal_(0,1).to(device)
b=torch.FloatTensor(8,128,1,1).normal_(0,1).to(device)
ab=(b-a)/8.
c=torch.FloatTensor(64,128,1,1).to(device)
for i in range(8):
   c[8*i:8*(i+1),:,:,:] = a + i*ab
c=Variable(c)
c_out= generator(c)

c_im = convert_img(c_out.data,8)
c_im

c=torch.FloatTensor(64,128,1,1).to(device)
c[9*1:9*(1+1)] = 1

torch.Tensor(10,128,1,1).shape

import numpy as np

from numpy import linspace
def interpolate(p1,p2,step=10):
  ratios=torch.linspace(0,2,steps=step)
  vec=torch.Tensor(10,128,1,1)
  i=0
  for ratio in ratios:
    #v = (1.0 - ratio) * p1 + ratio * p2
    m1=torch.mul(torch.sub(1.0,ratio), p1)
    m2=torch.mul(ratio,p2)
    add=torch.add(m1,m2)
    vec[i]=add.view(1,128,1,1)
    i=i+1
  return vec

ratios=torch.linspace(0,1,steps=10)
vec=torch.Tensor(10,128,1,1)
points =torch.randn(2,latent_size)
for ratio in ratios:
  m1=torch.mul(torch.sub(1.0,ratio), points[0])
  m2=torch.mul(ratio,points[1])
  add=torch.add(m1,m2)
  vec[0]=add.view(1,128,1,1)
  print(add.shape)
  break

vec[0].shape

vec=torch.Tensor(10,128,1,1)
vec[0]=1
vec[1].shape

points[0].shape

inter_polated.shape

latent_size=128
points =torch.randn(2,latent_size)
inter_polated = interpolate(points[0],points[1])
inter_polated=inter_polated#.to(device)
#out=generator(inter_polated)
#convert_img(out,10)

points[1]



import cv2
import os

frame = 'trainvid.avi'
file=[os.path.join(sample_dir,f) for  f in os.listdir(sample_dir) if 'generated' in f]
file.sort()

out=cv2.VideoWriter(frame,cv2.VideoWriter_fourcc(*'MP4V'),1,(530,530))
[out.write(cv2.imread(fname)) for fname in file]
out.release()

jovian.reset()
jovian.log_hyperparams(lr=lr,epochs=epochs)





plt.plot(metric_values[0][0],'*')
plt.plot(metric_values[0][3],'+')

metric_values





















































"""SCRAPING

"""

import os
import shutil
import requests
from urllib.request import urlretrieve
from bs4 import BeautifulSoup
from skimage import io

total_count = 0
root_url = 'https://myanimelist.net'
y_m_url = 'https://myanimelist.net/topanime.php?limit=0'

root_dir = './images'
#shutil.rmtree(root_dir, ignore_errors=True)

os.mkdir(root_dir)

out_dir = os.path.join(root_dir, '1')
out_dir

for i in range(0,1000,50):
  y='https://myanimelist.net/topanime.php?limit={}'.format(i)
  print(y)

##with name
c=0
for i in range(8000,10000,50):
    print('start',i)
    y_m_url='https://myanimelist.net/topmanga.php?limit={}'.format(i)
    response = requests.get(y_m_url)
    doc = BeautifulSoup(response.text)
    headpart=doc.find_all('td',class_="title al va-t clearfix word-break")
    print(len(headpart))
    o=0
    for link in headpart:
        o=o+1
        url=link.find('h3',class_='manga_h3')
        urlnext=url.find('a').attrs['href']
        pagenext = requests.get(urlnext)
        pagetext=BeautifulSoup(pagenext.text)
        imgurl=pagetext.find_all('a',class_="fw-n")
        #imgname=pagetext.find_all('h3',class_="h3_characters_voice_actors")
        length=len(imgname)
        l=0
        print('length',length,o)
        for imgpic in imgurl:
            try:
                img_tags = imgpic.find('img', attrs = { 'data-src': lambda x : x  and 'characters' in x})['data-srcset']
                if img_tags:
                    img_text=imgpic.find('img').attrs['alt'].strip()
                
                imgjpg=img_tags.split(',')[1].split('2x')[0]
                c=c+1
                l=l+1
                urlretrieve(imgjpg,os.path.join('./trial_images','{}.jpg'.format(img_text.split('/')[1] if '/' in img_text else img_text)))
            except TypeError:
                pass

def detect(filename, outname, cascade_file = "./lbpcascade_animeface.xml"):
    if not os.path.isfile(cascade_file):
        raise RuntimeError("%s: not found" % cascade_file)
    cascade = cv2.CascadeClassifier(cascade_file)
    image = cv2.imread(filename, cv2.IMREAD_COLOR)
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)

    faces = cascade.detectMultiScale(gray,
                                    # detector options
                                    #scaleFactor =1.5,
                                    #minNeighbors = 5,
                                    minSize = (24, 24)
                                    )
    
    if len(faces)>0:
        x, y, w, h = faces[0]
        #print(x, y, w, h)
        cv2.imwrite(outname, image[int(y-0.0*h): int(y+0.9*h), x: x+w])
        return True
    else:
        return False
  
    


ct = 0
k=0
l=0
#os.mkdir('./cropped_3')
files = os.listdir('./images_with_name/')

for f in files:
    l=l+1
    if detect(os.path.join('./images_with_name/',f), './cropped_3/{}'.format(f)):
        ct=ct+1
        print(f)
        k=k+1

import os
import re
path = "./images_with_name/"
files = os.listdir(path)
k=0
pattern = re.compile("[0-9]+")



  
#os.makdir('./image_1000_numbersname')
#print(f"Before Renaming: {files}")
for i in range(len(files)):
   ## if pattern.fullmatch(files[i].strip('.jpg')[0]):
        #shutil.move('./images_with_name/{}'.format(files[i]),'./image_extra_numbers/')
    os.rename(path+files[i], f"{path}{i}.jpg")
#print(f"After Renaming: {os.listdir(path)}")

shutil.move('./images_with_name/23.jpg','./image_extra_numbers')

c

len(os.listdir('./images'))





















